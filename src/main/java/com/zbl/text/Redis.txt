【Redisson分布式锁使用的正确姿势】
    public void doSomething() {
        try {
            // 上锁
            redisLock.lock();  //不能放到try的外面加锁，因为加锁异常，但是实际指令已经发送到服务端并执行，只是客户端读取响应超时，就会导致没有机会执行解锁的代码。
            // 处理业务
            ...
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
          // 释放锁
          redisLock.unlock();
        }
    }




【redis实现分布式锁】
    [使用哪个命令来实现分布式锁？]
        SET key value [EX seconds|PX milliseconds|EXAT timestamp|PXAT milliseconds-timestamp|KEEPTTL] [NX|XX] [GET]
    [redis实现分布式锁要点(来自redis官网)]
        Distributed locks are a very useful primitive in many environments where different processes must operate with
            shared resources in a mutually exclusive way.
        There are a number of libraries and blog posts describing how to implement a DLM (Distributed Lock Manager) with Redis,
            but every library uses a different approach,
            and many use a simple approach with lower guarantees compared to what can be achieved with slightly more complex designs.
        This page is an attempt to provide a more canonical algorithm to implement distributed locks with Redis.
            We propose an algorithm, called Redlock, which implements a DLM which we believe to be safer than the vanilla single instance approach.
            We hope that the community will analyze it, provide feedback,
            and use it as a starting point for the implementations or more complex or alternative designs.

        - Safety and Liveness guarantees
            We are going to model our design with just three properties that, from our point of view,
                are the minimum guarantees needed to use distributed locks in an effective way.
            1. Safety property: Mutual exclusion. At any given moment, only one client can hold a lock.
            2. Liveness property A: Deadlock free. Eventually it is always possible to acquire a lock,
                                    even if the client that locked a resource crashes or gets partitioned.
            3. Liveness property B: Fault tolerance. As long as the majority of Redis nodes are up,
                                    clients are able to acquire and release locks.


【redis普通分布式锁存在一定的缺陷】
    [高可用问题]
    客户端1在Redis的master节点上拿到了锁
    Master宕机了，存储锁的key还没有来得及同步到Slave上
    master故障，发生故障转移，slave节点升级为master节点
    客户端2从新的Master获取到了对应同一个资源的锁
    　　于是，客户端1和客户端2同时持有了同一个资源的锁。锁的安全性被打破了。针对这个问题。
        Redis作者antirez提出了RedLock算法来解决这个问题

    [业务线超时问题]
    节点1：如果设置锁的过期时间为30MS,但是业务线可能因为网络或者数据量峰值出现导致执行时间超过了30MS，
           那么这时redis已经把锁给释放了，但是业务线却仍然在执行
    节点2 这时去获取锁，发现锁可以获取成功，这就造成了 同时有两个节点在执行同一个业务逻辑，
          则无法保证业务的幂等性（数据加上版本号处理，但仍然会对累加结果造成重复性错误），
          会造成数据重复处理，或者日志主键ID重复，同一订单两次计算金额，客户两次扣款等问题

    [Redisson]
    Redisson在这个问题上加上了自动续时，如果锁已经被持有，那么另一个线程试图再次获取锁时，会把已存在的锁重置过期时间，
    就相当于延长了当前锁的时间从而避免过期造成幂等性问题(采用LUA脚本代码加锁，LUA脚本在redis中具有原子性操作。)
    watch dog自动延期机制
    客户端1加锁的锁key默认生存时间才30秒，如果业务执行时间超过了30秒，客户端1还是需要一直持有这把锁，怎么办呢？
    简单！只要客户端1一旦加锁成功，就会启动一个watch dog看门狗，他是一个后台线程，会每隔10秒检查一下，
    如果客户端1还持有锁key，那么就会不断的延长锁key的生存时间。

    [Redisson分布式锁的缺点]
    其实上面那种方案最大的问题，就是如果你对某个redis master实例，写入了myLock这种锁key的value，此时会异步复制给对应的master slave实例。
    但是这个过程中一旦发生redis master宕机，主备切换，redis slave变为了redis master。
    接着就会导致，客户端2来尝试加锁的时候，在新的redis master上完成了加锁，而客户端1也以为自己成功加了锁。
    此时就会导致多个客户端对一个分布式锁完成了加锁。
    这时系统在业务语义上一定会出现问题，导致各种脏数据的产生。
    所以这个就是redis cluster，或者是redis master-slave架构的主从异步复制导致的redis分布式锁的最大缺陷：
    在redis master实例宕机的时候，可能导致多个客户端同时完成加锁，
    如果要追求强一致性，那么只能考虑zookeeper分布式锁，当然它们各有自己的优缺点。

    [Redisson分布式锁的一些原理]
    获取锁：
          <T> RFuture<T> tryLockInnerAsync(long waitTime, long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand<T> command) {
                return evalWriteAsync(getRawName(), LongCodec.INSTANCE, command,
                        "if (redis.call('exists', KEYS[1]) == 0) then " +   //判断key是否存在，如果不存在直接获取锁
                                "redis.call('hincrby', KEYS[1], ARGV[2], 1); " +   //当前线程首次获取锁
                                "redis.call('pexpire', KEYS[1], ARGV[1]); " +    //设置过期时间
                                "return nil; " +
                                "end; " +
                                "if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then " +  //key存在，并且是持有锁的线程再次获取锁
                                "redis.call('hincrby', KEYS[1], ARGV[2], 1); " +    //重入标记+1
                                "redis.call('pexpire', KEYS[1], ARGV[1]); " +    //设置过期时间
                                "return nil; " +
                                "end; " +
                                "return redis.call('pttl', KEYS[1]);",
                        Collections.singletonList(getRawName()), unit.toMillis(leaseTime), getLockName(threadId));
          }

    释放锁：
        protected RFuture<Boolean> unlockInnerAsync(long threadId) {
            return evalWriteAsync(getRawName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,
                    "if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then " +  //如果key不存在了，直接返回
                            "return nil;" +
                            "end; " +
                            "local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); " +  //key还存在，重入次数减一
                            "if (counter > 0) then " +
                            "redis.call('pexpire', KEYS[1], ARGV[2]); " +  //如果重入次数还大于0，重新设置过期时间
                            "return 0; " +
                            "else " +
                            "redis.call('del', KEYS[1]); " +   //如果重入次数等于0，直接删除key
                            "redis.call('publish', KEYS[2], ARGV[1]); " +
                            "return 1; " +
                            "end; " +
                            "return nil;",
                    Arrays.asList(getRawName(), getChannelName()), LockPubSub.UNLOCK_MESSAGE, internalLockLeaseTime, getLockName(threadId));
        }



//https://blog.csdn.net/womenyiqilalala/article/details/105205532
【缓存雪崩】
     由于缓存层承载着大量请求，有效地保护了存储层，但是如果缓存层由于某些原因不可用（宕机）或者大量缓存由于超时时间相同在同一时间段失效（大批key失效/热点数据失效），
     大量请求直接到达存储层，存储层压力过大导致系统雪崩。

     [解决方案]
        1. 可以把缓存层设计成高可用的，即使个别节点、个别机器、甚至是机房宕掉，依然可以提供服务。利用sentinel或cluster实现。
        2. 采用多级缓存，本地进程作为一级缓存，redis作为二级缓存，不同级别的缓存设置的超时时间不同，即使某级缓存过期了，也有其他级别缓存兜底
        3. 缓存的过期时间用随机值，尽量让不同的key的过期时间不同（例如：定时任务新建大批量key，设置的过期时间相同）


【缓存击穿】
    系统中存在以下两个问题时需要引起注意：
        1. 当前key是一个热点key（例如一个秒杀活动），并发量非常大。
        2. 重建缓存不能在短时间完成，可能是一个复杂计算，例如复杂的SQL、多次IO、多个依赖等。
    在缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，甚至可能会让应用崩溃。

    [解决方案]
        1. 分布式互斥锁
         只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可。set(key,value,timeout)
        2. 永不过期
            从缓存层面来看，确实没有设置过期时间，所以不会出现热点key过期后产生的问题，也就是“物理”不过期。
            从功能层面来看，为每个value设置一个逻辑过期时间，当发现超过逻辑过期时间后，会使用单独的线程去更新缓
        2种方案对比：
        分布式互斥锁：这种方案思路比较简单，但是存在一定的隐患，如果在查询数据库 + 和 重建缓存（key失效后进行了大量的计算）时间过长，
            也可能会存在死锁和线程池阻塞的风险，高并发情景下吞吐量会大大降低！但是这种方法能够较好地降低后端存储负载，并在一致性上做得比较好。
        “永远不过期”：这种方案由于没有设置真正的过期时间，实际上已经不存在热点key产生的一系列危害，但是会存在数据不一致的情况，同时代码复杂度会增大。


【缓存穿透】
    缓存穿透是指查询一个根本不存在的数据，缓存层和持久层都不会命中。在日常工作中出于容错的考虑，如果从持久层查不到数据则不写入缓存层，
    缓存穿透将导致不存在的数据每次请求都要到持久层去查询，失去了缓存保护后端持久的意义

    缓存穿透问题可能会使后端存储负载加大，由于很多后端持久层不具备高并发性，甚至可能造成后端存储宕机。
        通常可以在程序中统计总调用数、缓存层命中数、如果同一个Key的缓存命中率很低，可能就是出现了缓存穿透问题。

    造成缓存穿透的基本原因有两个。第一，自身业务代码或者数据出现问题（例如：set 和 get 的key不一致），
        第二，一些恶意攻击、爬虫等造成大量空命中（爬取线上商城商品数据，超大循环递增商品的ID）

    [解决方案]
        1. 缓存空对象
       缓存空对象：是指在持久层没有命中的情况下，对key进行set （key,null）
       缓存空对象会有两个问题：第一，value为null 不代表不占用内存空间，空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间，
        比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除。第二，缓存层和存储层的数据会有一段时间窗口的不一致，
        可能会对业务有一定影响。例如过期时间设置为5分钟，如果此时存储层添加了这个数据，那此段时间就会出现缓存层和存储层数据的不一致，
        此时可以利用消息系统或者其他方式清除掉缓存层中的空对象

        2. 布隆过滤器拦截
        在访问缓存层和存储层之前，将存在的key用布隆过滤器提前保存起来，做第一层拦截，当收到一个对key请求时先用布隆过滤器验证是key否存在，
            如果存在在进入缓存层、存储层。可以使用bitmap做布隆过滤器。这种方法适用于数据命中不高、数据相对固定、实时性低的应用场景，代码维护较为复杂，
            但是缓存空间占用少。
        布隆过滤器实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。
            它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。
        算法描述：
        初始状态时，BloomFilter是一个长度为m的位数组，每一位都置为0。
        添加元素x时，x使用k个hash函数得到k个hash值，对m取余，对应的bit位设置为1。
        判断y是否属于这个集合，对y使用k个哈希函数得到k个哈希值，对m取余，所有对应的位置都是1，则认为y属于该集合（哈希冲突，可能存在误判），否则就认为y不属于该集合。
            可以通过增加哈希函数和增加二进制位数组的长度来降低错报率。
        错报原因：
        一个key映射数组上多位，一位会被多个key使用，也就是多对多的关系。如果一个key映射的所有位值为1，就判断为存在。
            但是可能会出现key1 和  key2 同时映射到下标为100的位，key1不存在，key2存在，这种情况下会发生错误率



【操作缓存的时候，到底是删除缓存呢，还是更新缓存？】
    1. 线程 A 先发起一个写操作，第一步先更新数据库
    2. 线程 B 再发起一个写操作，第二步更新了数据库
    3. 由于网络等原因，线程 B 先更新了缓存
    4. 线程 A 更新缓存。
    这时候，缓存保存的是A的数据（老数据），数据库保存的是B的数据（新数据），数据不一致了，脏数据出现啦。如果是删除缓存取代更新缓存则不会出现这个脏数据问题。

    更新缓存相对于删除缓存，还有两点劣势：
    - 如果你写入的缓存值，是经过复杂计算才得到的话。更新缓存频率高的话，就浪费性能啦。
    - 在写数据库场景多，读数据场景少的情况下，数据很多时候还没被读取到，又被更新了，这也浪费了性能呢(实际上，写多的场景，用缓存也不是很划算的,哈哈)



【redis的zset是如何实现的?为什么使用跳跃表而不使用其他的数据结构】


【redis的持久化方式】


【redis的集群方式，各有什么特点】


【redis cluster 的通信机制，说一下蜂巢】

